{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00a4cb42-ea51-4f18-9eaa-b01c16c55628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'poverty_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m tax_df = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mtaxdel.tsv\u001b[39m\u001b[33m'\u001b[39m, sep=\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8-sig\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 2. Poverty data (from the geojson you were using)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m poverty_df = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mpoverty_data.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTax Delinquencies: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(tax_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m records\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNeighborhoods: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(poverty_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m records\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/software/rhel9/manual/install/jupyterhub/hub.5.2.1/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/software/rhel9/manual/install/jupyterhub/hub.5.2.1/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = TextFileReader(filepath_or_buffer, **kwds)\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/software/rhel9/manual/install/jupyterhub/hub.5.2.1/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28mself\u001b[39m._make_engine(f, \u001b[38;5;28mself\u001b[39m.engine)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/software/rhel9/manual/install/jupyterhub/hub.5.2.1/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = get_handle(\n\u001b[32m   1881\u001b[39m     f,\n\u001b[32m   1882\u001b[39m     mode,\n\u001b[32m   1883\u001b[39m     encoding=\u001b[38;5;28mself\u001b[39m.options.get(\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m   1884\u001b[39m     compression=\u001b[38;5;28mself\u001b[39m.options.get(\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m   1885\u001b[39m     memory_map=\u001b[38;5;28mself\u001b[39m.options.get(\u001b[33m\"\u001b[39m\u001b[33mmemory_map\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[32m   1886\u001b[39m     is_text=is_text,\n\u001b[32m   1887\u001b[39m     errors=\u001b[38;5;28mself\u001b[39m.options.get(\u001b[33m\"\u001b[39m\u001b[33mencoding_errors\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstrict\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1888\u001b[39m     storage_options=\u001b[38;5;28mself\u001b[39m.options.get(\u001b[33m\"\u001b[39m\u001b[33mstorage_options\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m   1889\u001b[39m )\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/software/rhel9/manual/install/jupyterhub/hub.5.2.1/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m    876\u001b[39m             encoding=ioargs.encoding,\n\u001b[32m    877\u001b[39m             errors=errors,\n\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'poverty_data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the two datasets from your notebook\n",
    "print(\"Loading datasets...\")\n",
    "\n",
    "# 1. Tax delinquency data\n",
    "tax_df = pd.read_csv('taxdel.tsv', sep='\\t', encoding='utf-8-sig')\n",
    "\n",
    "# 2. Poverty data (from the geojson you were using)\n",
    "poverty_df = pd.read_csv('poverty_data.csv')\n",
    "\n",
    "print(f\"Tax Delinquencies: {len(tax_df)} records\")\n",
    "print(f\"Neighborhoods: {len(poverty_df)} records\")\n",
    "\n",
    "# Count tax delinquencies by neighborhood\n",
    "tax_with_neighborhood = tax_df[tax_df['neighborhood'].notna() & (tax_df['neighborhood'] != '')]\n",
    "tax_counts = tax_with_neighborhood['neighborhood'].value_counts()\n",
    "\n",
    "# Combine both datasets\n",
    "analysis_data = []\n",
    "\n",
    "for idx, row in poverty_df.iterrows():\n",
    "    neighborhood = row['hood']\n",
    "    pct_poverty = row['pct_under_']\n",
    "    tax_count = tax_counts.get(neighborhood, 0)\n",
    "    \n",
    "    analysis_data.append({\n",
    "        'neighborhood': neighborhood,\n",
    "        'tax_delinquencies': tax_count,\n",
    "        'pct_poverty': pct_poverty\n",
    "    })\n",
    "\n",
    "analysis_df = pd.DataFrame(analysis_data)\n",
    "\n",
    "# Calculate composite score (lower is better)\n",
    "max_tax = analysis_df['tax_delinquencies'].max()\n",
    "max_poverty = analysis_df['pct_poverty'].max()\n",
    "\n",
    "analysis_df['tax_score'] = (analysis_df['tax_delinquencies'] / max_tax) * 100\n",
    "analysis_df['poverty_score'] = (analysis_df['pct_poverty'] / max_poverty) * 100\n",
    "analysis_df['composite_score'] = (analysis_df['tax_score'] + analysis_df['poverty_score']) / 2\n",
    "\n",
    "# Sort by composite score\n",
    "analysis_df_sorted = analysis_df.sort_values('composite_score')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TOP 10 BEST NEIGHBORHOODS\")\n",
    "print(\"=\"*70)\n",
    "top_10 = analysis_df_sorted.head(10)\n",
    "for idx, row in top_10.iterrows():\n",
    "    print(f\"{row['neighborhood']:25} | Tax Delinq: {int(row['tax_delinquencies']):4} | Poverty: {row['pct_poverty']:.1f}% | Score: {row['composite_score']:.2f}\")\n",
    "\n",
    "best = analysis_df_sorted.iloc[0]\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"BEST NEIGHBORHOOD: {best['neighborhood']}\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Tax Delinquencies: {int(best['tax_delinquencies'])}\")\n",
    "print(f\"Poverty Rate: {best['pct_poverty']:.1f}%\")\n",
    "print(f\"Composite Score: {best['composite_score']:.2f}\")\n",
    "\n",
    "# Visualization: Scatter plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(analysis_df['pct_poverty'], analysis_df['tax_delinquencies'], \n",
    "           alpha=0.6, s=100, c=analysis_df['composite_score'], cmap='RdYlGn_r')\n",
    "plt.colorbar(label='Composite Score (Lower is Better)')\n",
    "plt.xlabel('Poverty Rate (%)', fontsize=12)\n",
    "plt.ylabel('Number of Tax Delinquent Properties', fontsize=12)\n",
    "plt.title('Pittsburgh Neighborhoods: Tax Delinquency vs Poverty Rate', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotate best neighborhood\n",
    "plt.annotate(best['neighborhood'], \n",
    "            xy=(best['pct_poverty'], best['tax_delinquencies']),\n",
    "            xytext=(10, 10), textcoords='offset points', \n",
    "            bbox=dict(boxstyle='round,pad=0.5', fc='green', alpha=0.5),\n",
    "            fontsize=10, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Bar chart: Top 10 Best vs Worst\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "best_10 = analysis_df_sorted.head(10)\n",
    "ax1.barh(range(len(best_10)), best_10['composite_score'], color='green', alpha=0.7)\n",
    "ax1.set_yticks(range(len(best_10)))\n",
    "ax1.set_yticklabels(best_10['neighborhood'])\n",
    "ax1.set_xlabel('Composite Score', fontsize=11)\n",
    "ax1.set_title('Top 10 BEST Neighborhoods', fontsize=13, fontweight='bold')\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "worst_10 = analysis_df_sorted.tail(10)\n",
    "ax2.barh(range(len(worst_10)), worst_10['composite_score'], color='red', alpha=0.7)\n",
    "ax2.set_yticks(range(len(worst_10)))\n",
    "ax2.set_yticklabels(worst_10['neighborhood'])\n",
    "ax2.set_xlabel('Composite Score', fontsize=11)\n",
    "ax2.set_title('Top 10 WORST Neighborhoods', fontsize=13, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8dbd53-2dfb-4d74-b893-f4a7b17dbdc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
